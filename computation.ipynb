{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7dac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Wrapper functions\n",
    "def train_markov_model(train_csv, save_dir, state_size=2):\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # if model.json already exists, skip training\n",
    "    model_json = save_dir / \"model.json\"\n",
    "    if model_json.exists():\n",
    "        print(f\"‚è≠Ô∏è Model already trained at {model_json}, skipping training.\")\n",
    "        return model_json\n",
    "\n",
    "    subprocess.run([\n",
    "        \"python3\", \"markov/train.py\",\n",
    "        \"--data_csv\", str(train_csv),\n",
    "        \"--save_dir\", str(save_dir),\n",
    "        \"--state_size\", str(state_size)\n",
    "    ], check=True)\n",
    "    print(f\"‚úÖ Model trained and saved to {model_json}\")\n",
    "    return model_json\n",
    "\n",
    "\n",
    "def evaluate_perplexity(model_path, data_dir, output_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Count CSVs in input and output dirs\n",
    "    input_files = list(data_dir.glob(\"*.csv\"))\n",
    "    output_files = list(output_dir.glob(\"*.csv\"))\n",
    "\n",
    "    if len(input_files) == len(output_files):\n",
    "        print(f\"‚è≠Ô∏è Perplexity already computed for all files in {output_dir}, skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚öôÔ∏è Running perplexity on {len(input_files)} input files...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"markov/perplexity.py\",\n",
    "        \"--model\", str(model_path),\n",
    "        \"--data_dir\", str(data_dir),\n",
    "        \"--output_dir\", str(output_dir),\n",
    "    ], check=True)\n",
    "\n",
    "    print(f\"‚úÖ Perplexity results saved to {output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "def test_markov_model(model_path, data_dir, output_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    input_files = list(data_dir.glob(\"*.csv\"))\n",
    "    output_files = list(output_dir.glob(\"*.csv\"))\n",
    "\n",
    "    if len(input_files) == len(output_files):\n",
    "        print(f\"‚è≠Ô∏è Test results already exist in {output_dir}, skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚öôÔ∏è Running top-k test on {len(input_files)} input files...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"markov/test.py\",\n",
    "        \"--model\", str(model_path),\n",
    "        \"--data_dir\", str(data_dir),\n",
    "        \"--output_dir\", str(output_dir),\n",
    "        \"--mode\", \"topk\",\n",
    "        \"--k_values\", \"1\", \"5\", \"10\"\n",
    "    ], check=True)\n",
    "\n",
    "    print(f\"‚úÖ Test results saved to {output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "def train_lstpm_model(train_csv, save_dir, nepochs=25):\n",
    "    \"\"\"\n",
    "    Preprocess + train LSTPM model, with skip checks.\n",
    "\n",
    "    Args:\n",
    "        train_csv (Path): path to training_set.csv\n",
    "        save_dir (Path): directory to save model\n",
    "\n",
    "    Returns:\n",
    "        (Path to trained model .m, Path to preprocessed_dir)\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    run_dir = save_dir.parent\n",
    "    preprocessed_dir = run_dir / \"preprocessed\"\n",
    "    metadata_path = run_dir / \"metadata.json\"\n",
    "    distance_path = run_dir / \"distance.pkl\"\n",
    "\n",
    "    model_path = save_dir / \"res.m\"\n",
    "\n",
    "    # ----- 1. Check if model already trained -----\n",
    "    if model_path.exists():\n",
    "        print(f\"‚è≠Ô∏è LSTPM model already trained at {model_path}, skipping training.\")\n",
    "        return model_path\n",
    "\n",
    "    # ----- 2. Check if preprocessed already done -----\n",
    "    input_csvs = list(train_csv.parent.glob(\"*.csv\"))\n",
    "    pk_files = list(preprocessed_dir.glob(\"*.pk\"))\n",
    "\n",
    "    if len(input_csvs) == len(pk_files) and len(pk_files) > 0:\n",
    "        print(f\"‚è≠Ô∏è Preprocessed data already present in {preprocessed_dir}, skipping preprocessing.\")\n",
    "    else:\n",
    "        print(\"‚öôÔ∏è Preprocessing LSTPM data...\")\n",
    "        result = subprocess.run([\n",
    "            \"python3\", \"LSTPM/train/preprocess.py\",\n",
    "            \"--in_dir\", str(train_csv.parent),\n",
    "            \"--training_set_name\", train_csv.stem,\n",
    "            \"--out_dir\", str(run_dir)\n",
    "        ], capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(\"‚ùå Preprocessing failed!\")\n",
    "            print(\"STDOUT:\\n\", result.stdout)\n",
    "            print(\"STDERR:\\n\", result.stderr)\n",
    "            raise RuntimeError(\"Preprocessing failed.\")\n",
    "        print(f\"‚úÖ Preprocessing completed, files saved to {preprocessed_dir}\")\n",
    "\n",
    "    # ----- 3. Train model -----\n",
    "    print(\"üéØ Training LSTPM...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"LSTPM/train/train.py\",\n",
    "        \"--data_pk\", str(preprocessed_dir / f\"{train_csv.stem}.pk\"),\n",
    "        \"--metadata_json\", str(metadata_path),\n",
    "        \"--distance\", str(distance_path),\n",
    "        \"--save_dir\", str(save_dir),\n",
    "        \"--batch_size\", \"512\",\n",
    "        \"--epochs\", str(nepochs)\n",
    "    ], check=True)\n",
    "    print(f\"‚úÖ LSTPM model saved at {model_path}\")\n",
    "\n",
    "    return model_path\n",
    "\n",
    "def test_lstpm_model(model_path, data_dir, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    if len(list(output_dir.glob(\"*.csv\"))) == len(list(Path(data_dir).glob(\"*.csv\"))):\n",
    "        print(f\"‚è≠Ô∏è LSTPM test results already exist in {output_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Testing LSTPM...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"LSTPM/train/test.py\",\n",
    "        \"--data_dir\", str(Path(data_dir) / \"preprocessed\"),\n",
    "        \"--model_m\", str(model_path),\n",
    "        \"--distance\", str(model_path.parent.parent / \"distance.pkl\"),\n",
    "        \"--mode\", \"topk\",\n",
    "        \"--k_values\", \"1\", \"5\", \"10\",\n",
    "        \"--output\", str(output_dir)\n",
    "    ], check=True)\n",
    "\n",
    "def evaluate_lstpm_perplexity(model_path, data_dir, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    preprocessed_dir = Path(data_dir) / \"preprocessed\"\n",
    "    if len(list(output_dir.glob(\"*.csv\"))) == len(list(Path(preprocessed_dir).glob(\"*.pk\"))):\n",
    "        print(f\"‚è≠Ô∏è LSTPM perplexity already computed for {output_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìà Evaluating LSTPM perplexity...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"LSTPM/train/perplexity.py\",\n",
    "        \"--data_dir\", str(preprocessed_dir),\n",
    "        \"--model_m\", str(model_path),\n",
    "        \"--distance\", str(model_path.parent.parent / \"distance.pkl\"),\n",
    "        \"--output\", str(output_dir)\n",
    "    ], check=True)\n",
    "\n",
    "# DeepMove Wrapper functions\n",
    "\n",
    "def train_deepmove_model(train_csv, save_dir, model_type):\n",
    "    save_dir = Path(save_dir)\n",
    "    run_dir = save_dir.parent\n",
    "    preprocessed_dir = run_dir / \"preprocessed\"\n",
    "    metadata_path = run_dir / \"metadata.json\"\n",
    "    train_pk = preprocessed_dir / f\"{train_csv.stem}.pk\"\n",
    "\n",
    "    # Skip if model already trained\n",
    "    if (save_dir / \"res.m\").exists():\n",
    "        print(f\"‚è≠Ô∏è DeepMove ({model_type}) model already trained at {save_dir}, skipping.\")\n",
    "        return save_dir / \"res.m\"\n",
    "\n",
    "    # Skip preprocessing if already done\n",
    "    if not train_pk.exists():\n",
    "        print(\"‚öôÔ∏è Preprocessing DeepMove data...\")\n",
    "        subprocess.run([\n",
    "            \"python3\", \"DeepMove/codes/preprocess.py\",\n",
    "            \"--in_dir\", str(train_csv.parent),\n",
    "            \"--training_set_name\", train_csv.stem,\n",
    "            \"--out_dir\", str(run_dir)\n",
    "        ], check=True)\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è Preprocessed file {train_pk} already exists, skipping preprocessing.\")\n",
    "\n",
    "    # Train\n",
    "    print(f\"üéØ Training DeepMove model ({model_type})...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"DeepMove/codes/main.py\",\n",
    "        \"--metadata_json\", str(metadata_path),\n",
    "        \"--model_mode\", model_type,\n",
    "        \"--data_path\", str(train_pk),\n",
    "        \"--epoch_max\", \"40\",\n",
    "        \"--save_dir\", str(save_dir),\n",
    "        \"--pretrain\", \"0\"\n",
    "    ], check=True)\n",
    "\n",
    "    return save_dir / \"res.m\"\n",
    "\n",
    "\n",
    "def test_deepmove_model(model_path, data_dir, output_dir, model_type):\n",
    "    output_dir = Path(output_dir)\n",
    "    if len(list(output_dir.glob(\"*.csv\"))) == len(list(Path(data_dir).glob(\"*.csv\"))):\n",
    "        print(f\"‚è≠Ô∏è DeepMove test results already exist in {output_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Testing DeepMove ({model_type})...\")\n",
    "    subprocess.run([\n",
    "        \"python3\", \"DeepMove/codes/test.py\",\n",
    "        \"--metadata_json\", str(model_path.parent.parent / \"metadata.json\"),\n",
    "        \"--model_mode\", model_type,\n",
    "        \"--model_path\", str(model_path),\n",
    "        \"--data_dir\", str(model_path.parent.parent / \"preprocessed\"),\n",
    "        \"--mode\", \"topk\",\n",
    "        \"--k_values\", \"1\", \"5\", \"10\", \"20\",\n",
    "        \"--output\", str(output_dir)\n",
    "    ], check=True)\n",
    "\n",
    "\n",
    "\n",
    "def perplexity_deepmove(model_path, data_dir, output_dir, model_type):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "    data_dir = Path(model_path.parent.parent / \"preprocessed\")\n",
    "    input_files = list(data_dir.glob(\"*.pk\"))\n",
    "    output_files = list(output_dir.glob(\"*.csv\"))\n",
    "\n",
    "    if len(input_files) == len(output_files):\n",
    "        print(f\"‚è≠Ô∏è DeepMove perplexity already computed for all files in {output_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìà Evaluating DeepMove ({model_type}) perplexity on {len(input_files)} files...\")\n",
    "\n",
    "    for pk_file in input_files:\n",
    "        out_file = output_dir / f\"{pk_file.stem}.csv\"\n",
    "        if out_file.exists():\n",
    "            print(f\"‚è≠Ô∏è Skipping already computed file: {out_file.name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Computing perplexity for {pk_file.name}...\")\n",
    "        subprocess.run([\n",
    "            \"python3\", \"DeepMove/codes/perplexity.py\",\n",
    "            \"--metadata_json\", str(model_path.parent.parent / \"metadata.json\"),\n",
    "            \"--model_mode\", model_type,\n",
    "            \"--model_path\", str(model_path),\n",
    "            \"--data_pk\", str(pk_file),\n",
    "            \"--output\", str(out_file)\n",
    "        ], check=True)\n",
    "\n",
    "    print(f\"‚úÖ DeepMove perplexity evaluation completed for all new files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6035905",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    \"ShenzhenUrban\": {\n",
    "        \"type1\": \"/home/akouamdj/mobleak-datasets/PreprocessedData/2SplittedData/ShenzhenUrban/NormalizationType1/Datasets\",\n",
    "        \"type2_home\": \"/home/akouamdj/mobleak-datasets/PreprocessedData/2SplittedData/ShenzhenUrban/NormalizationType2/Home/Datasets\",\n",
    "        \"type2_work\": \"/home/akouamdj/mobleak-datasets/PreprocessedData/2SplittedData/ShenzhenUrban/NormalizationType2/Work/Datasets\",\n",
    "        \"type3\": \"/home/akouamdj/mobleak-datasets/PreprocessedData/2SplittedData/ShenzhenUrban/NormalizationType3/Datasets\",\n",
    "    },\n",
    "    # Add more datasets later\n",
    "}\n",
    "\n",
    "MODELS = {\n",
    "    \"markov\": {\n",
    "        \"train\": train_markov_model,\n",
    "        \"test\": test_markov_model,\n",
    "        \"perplexity\": evaluate_perplexity,\n",
    "    },\n",
    "    \"lstpm\": {\n",
    "        \"train\": train_lstpm_model,\n",
    "        \"test\": test_lstpm_model,\n",
    "        \"perplexity\": evaluate_lstpm_perplexity,\n",
    "    },\n",
    "    \"deepmove_simple\": {\n",
    "        \"train\": lambda train_path, run_dir: train_deepmove_model(train_path, run_dir, \"simple\"),\n",
    "        \"test\": lambda model_path, data_dir, output_dir: test_deepmove_model(model_path, data_dir, output_dir, \"simple\"),\n",
    "        \"perplexity\": lambda model_path, data_dir, output_dir: perplexity_deepmove(model_path, data_dir, output_dir, \"simple\"),\n",
    "    },\n",
    "\n",
    "    \"deepmove_simple_long\": {\n",
    "        \"train\": lambda train_path, run_dir: train_deepmove_model(train_path, run_dir, \"simple_long\"),\n",
    "        \"test\": lambda model_path, data_dir, output_dir: test_deepmove_model(model_path, data_dir, output_dir, \"simple_long\"),\n",
    "        \"perplexity\": lambda model_path, data_dir, output_dir: perplexity_deepmove(model_path, data_dir, output_dir, \"simple_long\"),\n",
    "    },\n",
    "\n",
    "    \"deepmove_attn_avg_long_user\": {\n",
    "        \"train\": lambda train_path, run_dir: train_deepmove_model(train_path, run_dir, \"attn_avg_long_user\"),\n",
    "        \"test\": lambda model_path, data_dir, output_dir: test_deepmove_model(model_path, data_dir, output_dir, \"attn_avg_long_user\"),\n",
    "        \"perplexity\": lambda model_path, data_dir, output_dir: perplexity_deepmove(model_path, data_dir, output_dir, \"attn_avg_long_user\"),\n",
    "    },\n",
    "\n",
    "    \"deepmove_attn_local_long\": {\n",
    "        \"train\": lambda train_path, run_dir: train_deepmove_model(train_path, run_dir, \"attn_local_long\"),\n",
    "        \"test\": lambda model_path, data_dir, output_dir: test_deepmove_model(model_path, data_dir, output_dir, \"attn_local_long\"),\n",
    "        \"perplexity\": lambda model_path, data_dir, output_dir: perplexity_deepmove(model_path, data_dir, output_dir, \"attn_local_long\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Unified results directory\n",
    "OUTPUT_ROOT = Path(\"results/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9bec6f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_memorization_metrics(perplexity_dir, mapping_file):\n",
    "    \"\"\"\n",
    "    Given a folder with <cluster_X_perplexity.csv> and training_set.csv,\n",
    "    compute the 3 memorization metrics per training tid.\n",
    "    \"\"\"\n",
    "    perplexity_dir = Path(perplexity_dir)\n",
    "\n",
    "    # Support both filenames\n",
    "    training_perp_path = perplexity_dir / \"training_set_perplexity.csv\"\n",
    "    if not training_perp_path.exists():\n",
    "        training_perp_path = perplexity_dir / \"training_set.csv\"\n",
    "\n",
    "    training_df = pd.read_csv(training_perp_path)\n",
    "    # print(training_df.head())\n",
    "\n",
    "    # Support both column names: 'tid' or 'user'\n",
    "    id_col = \"tid\" if \"tid\" in training_df.columns else \"user\"\n",
    "\n",
    "    training_dict = training_df.set_index(id_col)[\"perplexity\"].to_dict()\n",
    "    mapping_df = pd.read_csv(mapping_file)\n",
    "\n",
    "    if \"cluster_file\" in mapping_df.columns:\n",
    "        type3 = False\n",
    "        mapping_dict = mapping_df.set_index(\"cluster_file\")[\"representant_tid\"].to_dict()\n",
    "    else:\n",
    "        # type 3\n",
    "        type3 = True\n",
    "        mapping_df['reference_file'] = mapping_df['device_id'].apply(lambda x: f\"{x}.csv\")\n",
    "        mapping_dict = mapping_df.set_index(\"reference_file\")[\"training_tid\"].to_dict()\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for ref_file in perplexity_dir.glob(\"*.csv\"):\n",
    "        cluster_id = ref_file.stem.replace(\"_perplexity\", \"\") + \".csv\"\n",
    "        if cluster_id == \"training_set.csv\" or cluster_id == \"training_set_perplexity.csv\":\n",
    "            continue\n",
    "        print(ref_file)\n",
    "        ref_df = pd.read_csv(ref_file)\n",
    "        if ref_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Adapt to tid/user here as well\n",
    "        ref_id_col = \"tid\" if \"tid\" in ref_df.columns else \"user\"\n",
    "\n",
    "        training_tid_val = mapping_dict.get(cluster_id)\n",
    "        if training_tid_val not in training_dict:\n",
    "            continue\n",
    "\n",
    "        train_perp = training_dict[training_tid_val]\n",
    "\n",
    "        result_row = {\n",
    "            \"tid\": training_tid_val,\n",
    "            \"cluster_id\": cluster_id,\n",
    "        }\n",
    "\n",
    "        if type3:\n",
    "            for perturbation in ['substitute', 'stationary', 'shuffle']:\n",
    "                mapping_df_perturbed = mapping_df[mapping_df['perturbation'] == perturbation]\n",
    "                ref_df_perturbed = ref_df[ref_df[ref_id_col].isin(mapping_df_perturbed['reference_tid'])]\n",
    "\n",
    "                ref_perps = ref_df_perturbed[\"perplexity\"].values\n",
    "                ref_mean = np.mean(ref_perps)\n",
    "                rank = np.sum(ref_perps <= train_perp) + 1\n",
    "                exposure = np.log2(len(ref_perps)) - np.log2(rank)\n",
    "                percentile = (rank - 1) / len(ref_perps)\n",
    "                gap = train_perp - ref_mean\n",
    "\n",
    "                result_row.update({\n",
    "                    f\"train_perplexity_{perturbation}\": train_perp,\n",
    "                    f\"mean_ref_perplexity_{perturbation}\": ref_mean,\n",
    "                    f\"exposure_{perturbation}\": exposure,\n",
    "                    f\"percentile_{perturbation}\": percentile,\n",
    "                    f\"gap_{perturbation}\": gap,\n",
    "                })\n",
    "\n",
    "        # General (non-perturbed) cluster\n",
    "        ref_perps = ref_df[\"perplexity\"].values\n",
    "        ref_mean = np.mean(ref_perps)\n",
    "        rank = np.sum(ref_perps <= train_perp) + 1\n",
    "        exposure = np.log2(len(ref_perps)) - np.log2(rank)\n",
    "        percentile = (rank - 1) / len(ref_perps)\n",
    "        gap = train_perp - ref_mean\n",
    "\n",
    "        result_row.update({\n",
    "            \"train_perplexity\": train_perp,\n",
    "            \"mean_ref_perplexity\": ref_mean,\n",
    "            \"exposure\": exposure,\n",
    "            \"percentile\": percentile,\n",
    "            \"gap\": gap,\n",
    "        })\n",
    "\n",
    "        rows.append(result_row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61b4bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_memorization_test(dataset_name, type_name, dataset_path, model_name):\n",
    "    print(f\"\\nüöÄ Running: {model_name.upper()} | {dataset_name} | {type_name}\")\n",
    "    \n",
    "    model = MODELS[model_name]\n",
    "    dataset_path = Path(dataset_path)\n",
    "    training_file = dataset_path / \"training_set.csv\"\n",
    "    mapping_file = dataset_path / \"representant_mapping.txt\"\n",
    "\n",
    "    if not training_file.exists():\n",
    "        print(f\"‚ö†Ô∏è No training set found in {dataset_path}\")\n",
    "        return\n",
    "\n",
    "    run_dir = OUTPUT_ROOT /   dataset_name / model_name/ type_name\n",
    "    model_dir = run_dir / \"model\"\n",
    "    perplexity_dir = run_dir / \"perplexity\"\n",
    "    test_dir = run_dir / \"test\"\n",
    "\n",
    "    # Train\n",
    "    model_path = model[\"train\"](training_file, model_dir)\n",
    "\n",
    "    # Perplexity\n",
    "    model[\"perplexity\"](model_path, run_dir, perplexity_dir)\n",
    "\n",
    "    # Metrics\n",
    "    metrics_path = run_dir / \"memorization_metrics.csv\"\n",
    "    if metrics_path.exists():\n",
    "        print(f\"‚è≠Ô∏è Metrics already exist at {metrics_path}\")\n",
    "    else:\n",
    "        metrics_df = compute_memorization_metrics(perplexity_dir, mapping_file)\n",
    "        metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"‚úÖ Metrics saved to: {metrics_path}\")\n",
    "\n",
    "    # Test\n",
    "    #model[\"test\"](model_path, dataset_path, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca668c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running: DEEPMOVE_ATTN_AVG_LONG_USER | ShenzhenUrban | type1\n",
      "‚è≠Ô∏è DeepMove (attn_avg_long_user) model already trained at results/ShenzhenUrban/deepmove_attn_avg_long_user/type1/model, skipping.\n",
      "‚è≠Ô∏è DeepMove perplexity already computed for all files in results/ShenzhenUrban/deepmove_attn_avg_long_user/type1/perplexity\n",
      "‚è≠Ô∏è Metrics already exist at results/ShenzhenUrban/deepmove_attn_avg_long_user/type1/memorization_metrics.csv\n",
      "‚úÖ Metrics saved to: results/ShenzhenUrban/deepmove_attn_avg_long_user/type1/memorization_metrics.csv\n",
      "\n",
      "üöÄ Running: DEEPMOVE_ATTN_AVG_LONG_USER | ShenzhenUrban | type2_home\n",
      "‚è≠Ô∏è DeepMove (attn_avg_long_user) model already trained at results/ShenzhenUrban/deepmove_attn_avg_long_user/type2_home/model, skipping.\n",
      "üìà Evaluating DeepMove (attn_avg_long_user) perplexity on 2001 files...\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_20869632_20869728.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_19566288_19566384.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_16630368_16630464.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_35834016_35834112.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_15360288_15360384.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_35524512_35524608.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_12730896_12730992.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_29466432_29466528.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_29842176_29842272.csv\n",
      "‚è≠Ô∏è Skipping already computed file: cluster_19023696_19023792.csv\n",
      "‚öôÔ∏è Computing perplexity for cluster_50055696_50055792.pk...\n",
      "Processing results/ShenzhenUrban/deepmove_attn_avg_long_user/type2_home/preprocessed/cluster_50055696_50055792.pk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Computing perplexity for cluster_48838416_48838512.pk...\n",
      "Processing results/ShenzhenUrban/deepmove_attn_avg_long_user/type2_home/preprocessed/cluster_48838416_48838512.pk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Computing perplexity for cluster_23054112_23054208.pk...\n"
     ]
    }
   ],
   "source": [
    "#ALL_MODELS = [\"markov\", \"lstpm\", \"deepmove_simple\", \"deepmove_simple_long\", \"deepmove_attn_avg_long_user\", \"deepmove_attn_local_long\"]\n",
    "ALL_MODELS = [\"deepmove_attn_avg_long_user\", \"deepmove_attn_local_long\"]  \n",
    "\n",
    "for model_name in ALL_MODELS:\n",
    "    for dataset_name, type_paths in DATASETS.items():\n",
    "        for type_name, path in type_paths.items():\n",
    "            run_memorization_test(dataset_name, type_name, path, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addeb76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
